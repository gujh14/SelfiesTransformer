{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from model import SelfiesTransformer\n",
    "from custom_selfies_dataset import CustomSELFIESDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PICKLED_DATASET_DIR = \"./dataset_pickles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBBP\n",
    "binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'bbbp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(PICKLED_DATASET_DIR, DATASET+\"_data.pickle\")\n",
    "label_path= os.path.join(PICKLED_DATASET_DIR, DATASET+\"_label.pickle\")\n",
    "sym2idx_path = os.path.join(PICKLED_DATASET_DIR, \"symbol2idx_\"+DATASET+\".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "with open(label_path, \"rb\") as f:\n",
    "    y = pickle.load(f)\n",
    "with open(sym2idx_path, \"rb\") as f:\n",
    "    symbol2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996 1996\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomSELFIESDataset(X_train, y_train)\n",
    "val_dataset = CustomSELFIESDataset(X_val, y_val)\n",
    "test_dataset = CustomSELFIESDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_dict\": symbol2idx,\n",
    "    \"max_length\": len(X_train[0]),\n",
    "    \"dim\": 32,\n",
    "    \"n_classes\": 1, # binary classification\n",
    "    \"heads\": 2,\n",
    "    \"mlp_dim\": 16,\n",
    "    \"depth\": 2,\n",
    "    \"dim_head\": 32,\n",
    "    \"dropout\": 0.1,\n",
    "    \"emb_dropout\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelfiesTransformer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0001 | train loss: 0.61484 | train accuracy: 0.2222 | valid loss: 0.59523 | valid accuracy: 0.2180\n",
      "epoch: 0002 | train loss: 0.60101 | train accuracy: 0.2222 | valid loss: 0.58254 | valid accuracy: 0.2180\n",
      "epoch: 0003 | train loss: 0.58884 | train accuracy: 0.2222 | valid loss: 0.57228 | valid accuracy: 0.2180\n",
      "epoch: 0004 | train loss: 0.57640 | train accuracy: 0.2222 | valid loss: 0.56382 | valid accuracy: 0.2180\n",
      "epoch: 0005 | train loss: 0.57784 | train accuracy: 0.2222 | valid loss: 0.55709 | valid accuracy: 0.2180\n",
      "epoch: 0006 | train loss: 0.56692 | train accuracy: 0.2222 | valid loss: 0.55075 | valid accuracy: 0.2180\n",
      "epoch: 0007 | train loss: 0.56085 | train accuracy: 0.2222 | valid loss: 0.54621 | valid accuracy: 0.2180\n",
      "epoch: 0008 | train loss: 0.55795 | train accuracy: 0.2222 | valid loss: 0.54306 | valid accuracy: 0.2180\n",
      "epoch: 0009 | train loss: 0.55449 | train accuracy: 0.2222 | valid loss: 0.53975 | valid accuracy: 0.2180\n",
      "epoch: 0010 | train loss: 0.54923 | train accuracy: 0.2222 | valid loss: 0.53630 | valid accuracy: 0.2180\n",
      "epoch: 0011 | train loss: 0.54791 | train accuracy: 0.2222 | valid loss: 0.53429 | valid accuracy: 0.2180\n",
      "epoch: 0012 | train loss: 0.54300 | train accuracy: 0.2222 | valid loss: 0.53236 | valid accuracy: 0.2180\n",
      "epoch: 0013 | train loss: 0.54521 | train accuracy: 0.2222 | valid loss: 0.53077 | valid accuracy: 0.2180\n",
      "epoch: 0014 | train loss: 0.54279 | train accuracy: 0.2222 | valid loss: 0.52889 | valid accuracy: 0.2180\n",
      "epoch: 0015 | train loss: 0.54040 | train accuracy: 0.2222 | valid loss: 0.52807 | valid accuracy: 0.2180\n",
      "epoch: 0016 | train loss: 0.54270 | train accuracy: 0.2222 | valid loss: 0.52681 | valid accuracy: 0.2180\n",
      "epoch: 0017 | train loss: 0.53687 | train accuracy: 0.2222 | valid loss: 0.52691 | valid accuracy: 0.2180\n",
      "epoch: 0018 | train loss: 0.53424 | train accuracy: 0.2222 | valid loss: 0.52535 | valid accuracy: 0.2180\n",
      "epoch: 0019 | train loss: 0.53817 | train accuracy: 0.2222 | valid loss: 0.52509 | valid accuracy: 0.2180\n",
      "epoch: 0020 | train loss: 0.53209 | train accuracy: 0.2222 | valid loss: 0.52430 | valid accuracy: 0.2180\n",
      "epoch: 0021 | train loss: 0.53924 | train accuracy: 0.2222 | valid loss: 0.52392 | valid accuracy: 0.2180\n",
      "epoch: 0022 | train loss: 0.53506 | train accuracy: 0.2222 | valid loss: 0.52392 | valid accuracy: 0.2180\n",
      "epoch: 0023 | train loss: 0.54104 | train accuracy: 0.2222 | valid loss: 0.52365 | valid accuracy: 0.2180\n",
      "epoch: 0024 | train loss: 0.53177 | train accuracy: 0.2222 | valid loss: 0.52344 | valid accuracy: 0.2180\n",
      "epoch: 0025 | train loss: 0.52963 | train accuracy: 0.2222 | valid loss: 0.52292 | valid accuracy: 0.2180\n",
      "epoch: 0026 | train loss: 0.53882 | train accuracy: 0.2222 | valid loss: 0.52340 | valid accuracy: 0.2180\n",
      "epoch: 0027 | train loss: 0.53497 | train accuracy: 0.2222 | valid loss: 0.52396 | valid accuracy: 0.2180\n",
      "epoch: 0028 | train loss: 0.53264 | train accuracy: 0.2222 | valid loss: 0.52252 | valid accuracy: 0.2180\n",
      "epoch: 0029 | train loss: 0.53253 | train accuracy: 0.2222 | valid loss: 0.52312 | valid accuracy: 0.2180\n",
      "epoch: 0030 | train loss: 0.53289 | train accuracy: 0.2222 | valid loss: 0.52236 | valid accuracy: 0.2180\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(30):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    # temp = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        # temp += len(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        #print(inputs.get_device())\n",
    "        #print(labels.get_device())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        labels_pred = softmax(outputs).argmax(1)\n",
    "        \n",
    "        # print(labels)\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_correct += (labels == labels_pred.unsqueeze(-1)).float().sum() # ???\n",
    "        train_loss += [loss.item()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        val_correct = 0\n",
    "        for _, val_data in enumerate(val_dataloader, 0):\n",
    "            v_inputs, v_labels = val_data\n",
    "            v_inputs = v_inputs.to(device)\n",
    "            v_labels = v_labels.unsqueeze(-1).to(device)\n",
    "            \n",
    "            v_outputs = model(v_inputs)\n",
    "            v_labels_pred = softmax(v_outputs).argmax(1)\n",
    "            \n",
    "            v_loss = criterion(v_outputs, v_labels)\n",
    "            val_loss += [v_loss.item()]\n",
    "            val_correct += (v_labels == v_labels_pred.unsqueeze(-1)).float().sum()\n",
    "    \n",
    "    accuracy_train = train_correct / len(X_train)\n",
    "    accuracy_val = val_correct / len(X_val)\n",
    "    print(\"epoch: %04d | train loss: %.5f | train accuracy: %.4f | valid loss: %.5f | valid accuracy: %.4f\" %\n",
    "         (epoch + 1, np.mean(train_loss), accuracy_train, np.mean(val_loss), accuracy_val))\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lipophilicity\n",
    "regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'lipo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(PICKLED_DATASET_DIR, DATASET+\"_data.pickle\")\n",
    "label_path= os.path.join(PICKLED_DATASET_DIR, DATASET+\"_label.pickle\")\n",
    "sym2idx_path = os.path.join(PICKLED_DATASET_DIR, \"symbol2idx_\"+DATASET+\".pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "with open(label_path, \"rb\") as f:\n",
    "    y = pickle.load(f)\n",
    "with open(sym2idx_path, \"rb\") as f:\n",
    "    symbol2idx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4194 4194\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2516 839 839\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomSELFIESDataset(X_train, y_train)\n",
    "val_dataset = CustomSELFIESDataset(X_val, y_val)\n",
    "test_dataset = CustomSELFIESDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"symbol2idx_lipo.pickle\", \"rb\") as f:\n",
    "    symbol2idx_lipo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_dict\": symbol2idx,\n",
    "    \"max_length\": len(X_train[0]),\n",
    "    \"dim\": 32,\n",
    "    \"n_classes\": 1, # regression\n",
    "    \"heads\": 2,\n",
    "    \"mlp_dim\": 16,\n",
    "    \"depth\": 2,\n",
    "    \"dim_head\": 32,\n",
    "    \"dropout\": 0.1,\n",
    "    \"emb_dropout\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelfiesTransformer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "lr = 0.001 # 0.0001\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0001 | train loss: 1.62360 | valid loss: 1.38040\n",
      "epoch: 0002 | train loss: 1.34807 | valid loss: 1.23110\n",
      "epoch: 0003 | train loss: 1.24456 | valid loss: 1.41055\n",
      "epoch: 0004 | train loss: 1.20306 | valid loss: 1.13739\n",
      "epoch: 0005 | train loss: 1.18320 | valid loss: 1.15619\n",
      "epoch: 0006 | train loss: 1.17312 | valid loss: 1.14489\n",
      "epoch: 0007 | train loss: 1.16015 | valid loss: 1.15669\n",
      "epoch: 0008 | train loss: 1.13301 | valid loss: 1.13610\n",
      "epoch: 0009 | train loss: 1.10797 | valid loss: 1.13433\n",
      "epoch: 0010 | train loss: 1.11741 | valid loss: 1.11912\n",
      "epoch: 0011 | train loss: 1.09624 | valid loss: 1.12030\n",
      "epoch: 0012 | train loss: 1.09728 | valid loss: 1.12407\n",
      "epoch: 0013 | train loss: 1.06992 | valid loss: 1.16924\n",
      "epoch: 0014 | train loss: 1.06500 | valid loss: 1.12765\n",
      "epoch: 0015 | train loss: 1.05079 | valid loss: 1.09100\n",
      "epoch: 0016 | train loss: 1.03690 | valid loss: 1.13246\n",
      "epoch: 0017 | train loss: 1.07511 | valid loss: 1.06088\n",
      "epoch: 0018 | train loss: 1.03054 | valid loss: 1.07462\n",
      "epoch: 0019 | train loss: 1.00300 | valid loss: 1.08985\n",
      "epoch: 0020 | train loss: 1.02089 | valid loss: 1.08745\n",
      "epoch: 0021 | train loss: 1.00387 | valid loss: 1.16103\n",
      "epoch: 0022 | train loss: 1.00419 | valid loss: 1.04916\n",
      "epoch: 0023 | train loss: 0.93876 | valid loss: 1.13527\n",
      "epoch: 0024 | train loss: 0.96690 | valid loss: 1.10938\n",
      "epoch: 0025 | train loss: 0.94068 | valid loss: 1.08147\n",
      "epoch: 0026 | train loss: 0.93025 | valid loss: 1.08897\n",
      "epoch: 0027 | train loss: 0.94734 | valid loss: 1.15530\n",
      "epoch: 0028 | train loss: 0.91924 | valid loss: 1.17189\n",
      "epoch: 0029 | train loss: 0.93204 | valid loss: 1.10304\n",
      "epoch: 0030 | train loss: 0.92320 | valid loss: 1.10103\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(30):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        #print(inputs.get_device())\n",
    "        #print(labels.get_device())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # labels_pred = softmax(outputs).argmax(1)\n",
    "        \n",
    "        # print(labels)\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # train_correct += (labels == labels_pred.unsqueeze(-1)).float().sum() # ???\n",
    "        train_loss += [loss.item()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        for _, val_data in enumerate(val_dataloader, 0):\n",
    "            v_inputs, v_labels = val_data\n",
    "            v_inputs = v_inputs.to(device)\n",
    "            v_labels = v_labels.unsqueeze(-1).to(device)\n",
    "            v_outputs = model(v_inputs)\n",
    "            v_loss = criterion(v_outputs, v_labels)\n",
    "            val_loss += [v_loss.item()]\n",
    "    # accuracy_train = train_correct / len(X_train)\n",
    "    print(\"epoch: %04d | train loss: %.5f | valid loss: %.5f\" %\n",
    "         (epoch + 1, np.mean(train_loss), np.mean(val_loss)))\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
