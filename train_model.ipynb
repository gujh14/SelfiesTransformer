{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# from model import PositionalEncoding, SELFIES_Transformer\n",
    "from model import SelfiesTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_selfies_dataset import CustomSELFIESDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BBBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bbbp_data.pickle\", \"rb\") as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bbbp_label.pickle\", \"rb\") as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1996 1996\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553\n",
      "443\n"
     ]
    }
   ],
   "source": [
    "print(y.count(1)) # number of positive samples\n",
    "print(y.count(0)) # number of negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomSELFIESDataset(X_train, y_train)\n",
    "test_dataset = CustomSELFIESDataset(X_test, y_test)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([36, 15, 29, 65, 36, 36, 29, 64, 18, 36, 36, 55, 29, 64, 13, 36, 28, 15,\n",
       "         36, 36, 28, 14, 36, 15, 36, 15, 36, 15, 64, 13, 20, 36, 36, 36, 64,  4,\n",
       "         36, 61, 36, 15, 36, 15, 65, 64, 14, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
       "         79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
       "         79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79,\n",
       "         79, 79, 79, 79, 79, 79, 79, 79, 79, 79]),\n",
       " tensor(1.))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"symbol2idx_bbbp.pickle\", \"rb\") as f:\n",
    "    symbol2idx_bbbp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_dict\": symbol2idx_bbbp,\n",
    "    \"max_length\": len(X_train[0]),\n",
    "    \"dim\": 32,\n",
    "    \"n_classes\": 1, # binary classification\n",
    "    \"heads\": 2,\n",
    "    \"mlp_dim\": 16,\n",
    "    \"depth\": 2,\n",
    "    \"dim_head\": 32,\n",
    "    \"dropout\": 0.1,\n",
    "    \"emb_dropout\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelfiesTransformer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0001 | train loss: 0.60085 | train_accuracy: 0.2212\n",
      "epoch: 0002 | train loss: 0.58838 | train_accuracy: 0.2212\n",
      "epoch: 0003 | train loss: 0.57700 | train_accuracy: 0.2212\n",
      "epoch: 0004 | train loss: 0.56928 | train_accuracy: 0.2212\n",
      "epoch: 0005 | train loss: 0.55883 | train_accuracy: 0.2212\n",
      "epoch: 0006 | train loss: 0.55324 | train_accuracy: 0.2212\n",
      "epoch: 0007 | train loss: 0.54874 | train_accuracy: 0.2212\n",
      "epoch: 0008 | train loss: 0.54200 | train_accuracy: 0.2212\n",
      "epoch: 0009 | train loss: 0.54154 | train_accuracy: 0.2212\n",
      "epoch: 0010 | train loss: 0.53797 | train_accuracy: 0.2212\n",
      "epoch: 0011 | train loss: 0.53791 | train_accuracy: 0.2212\n",
      "epoch: 0012 | train loss: 0.53934 | train_accuracy: 0.2212\n",
      "epoch: 0013 | train loss: 0.53387 | train_accuracy: 0.2212\n",
      "epoch: 0014 | train loss: 0.53239 | train_accuracy: 0.2212\n",
      "epoch: 0015 | train loss: 0.53592 | train_accuracy: 0.2212\n",
      "epoch: 0016 | train loss: 0.53137 | train_accuracy: 0.2212\n",
      "epoch: 0017 | train loss: 0.53444 | train_accuracy: 0.2212\n",
      "epoch: 0018 | train loss: 0.53013 | train_accuracy: 0.2212\n",
      "epoch: 0019 | train loss: 0.53202 | train_accuracy: 0.2212\n",
      "epoch: 0020 | train loss: 0.52966 | train_accuracy: 0.2212\n",
      "epoch: 0021 | train loss: 0.53132 | train_accuracy: 0.2212\n",
      "epoch: 0022 | train loss: 0.53034 | train_accuracy: 0.2212\n",
      "epoch: 0023 | train loss: 0.53074 | train_accuracy: 0.2212\n",
      "epoch: 0024 | train loss: 0.53125 | train_accuracy: 0.2212\n",
      "epoch: 0025 | train loss: 0.52966 | train_accuracy: 0.2212\n",
      "epoch: 0026 | train loss: 0.53312 | train_accuracy: 0.2212\n",
      "epoch: 0027 | train loss: 0.52916 | train_accuracy: 0.2212\n",
      "epoch: 0028 | train loss: 0.53233 | train_accuracy: 0.2212\n",
      "epoch: 0029 | train loss: 0.52726 | train_accuracy: 0.2212\n",
      "epoch: 0030 | train loss: 0.52802 | train_accuracy: 0.2212\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(30):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    # temp = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        # temp += len(inputs)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        #print(inputs.get_device())\n",
    "        #print(labels.get_device())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        labels_pred = softmax(outputs).argmax(1)\n",
    "        \n",
    "        # print(labels)\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_correct += (labels == labels_pred.unsqueeze(-1)).float().sum() # ???\n",
    "        train_loss += [loss.item()]\n",
    "    \n",
    "    accuracy_train = train_correct / len(X_train)\n",
    "    print(\"epoch: %04d | train loss: %.5f | train_accuracy: %.4f\" %\n",
    "         (epoch + 1, np.mean(train_loss), accuracy_train))\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lipophilicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lipo_data.pickle\", \"rb\") as f:\n",
    "    X = pickle.load(f)\n",
    "with open(\"lipo_label.pickle\", \"rb\") as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4194 4194\n"
     ]
    }
   ],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2516 839 839\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomSELFIESDataset(X_train, y_train)\n",
    "val_dataset = CustomSELFIESDataset(X_val, y_val)\n",
    "test_dataset = CustomSELFIESDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"symbol2idx_lipo.pickle\", \"rb\") as f:\n",
    "    symbol2idx_lipo = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vocab_dict\": symbol2idx_lipo,\n",
    "    \"max_length\": len(X_train[0]),\n",
    "    \"dim\": 32,\n",
    "    \"n_classes\": 1, # regression\n",
    "    \"heads\": 2,\n",
    "    \"mlp_dim\": 16,\n",
    "    \"depth\": 2,\n",
    "    \"dim_head\": 32,\n",
    "    \"dropout\": 0.1,\n",
    "    \"emb_dropout\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelfiesTransformer(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "lr = 0.001 # 0.0001\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0001 | train loss: 1.65021\n",
      "epoch: 0002 | train loss: 1.28181\n",
      "epoch: 0003 | train loss: 1.23099\n",
      "epoch: 0004 | train loss: 1.18525\n",
      "epoch: 0005 | train loss: 1.15601\n",
      "epoch: 0006 | train loss: 1.14051\n",
      "epoch: 0007 | train loss: 1.13146\n",
      "epoch: 0008 | train loss: 1.10298\n",
      "epoch: 0009 | train loss: 1.07579\n",
      "epoch: 0010 | train loss: 1.04971\n",
      "epoch: 0011 | train loss: 1.05730\n",
      "epoch: 0012 | train loss: 1.04330\n",
      "epoch: 0013 | train loss: 1.01596\n",
      "epoch: 0014 | train loss: 1.02465\n",
      "epoch: 0015 | train loss: 1.01211\n",
      "epoch: 0016 | train loss: 0.99032\n",
      "epoch: 0017 | train loss: 0.99361\n",
      "epoch: 0018 | train loss: 0.97532\n",
      "epoch: 0019 | train loss: 0.96208\n",
      "epoch: 0020 | train loss: 0.96136\n",
      "epoch: 0021 | train loss: 0.95580\n",
      "epoch: 0022 | train loss: 0.93535\n",
      "epoch: 0023 | train loss: 0.92839\n",
      "epoch: 0024 | train loss: 0.94336\n",
      "epoch: 0025 | train loss: 0.90548\n",
      "epoch: 0026 | train loss: 0.89001\n",
      "epoch: 0027 | train loss: 0.90453\n",
      "epoch: 0028 | train loss: 0.90156\n",
      "epoch: 0029 | train loss: 0.86714\n",
      "epoch: 0030 | train loss: 0.86573\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(30):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        #print(inputs.get_device())\n",
    "        #print(labels.get_device())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # labels_pred = softmax(outputs).argmax(1)\n",
    "        \n",
    "        # print(labels)\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # train_correct += (labels == labels_pred.unsqueeze(-1)).float().sum() # ???\n",
    "        train_loss += [loss.item()]\n",
    "    \n",
    "    # accuracy_train = train_correct / len(X_train)\n",
    "    print(\"epoch: %04d | train loss: %.5f\" %\n",
    "         (epoch + 1, np.mean(train_loss)))\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0001 | train loss: 1.70656 | valid loss: 1.45706\n",
      "epoch: 0002 | train loss: 1.40156 | valid loss: 1.42241\n",
      "epoch: 0003 | train loss: 1.30607 | valid loss: 1.19506\n",
      "epoch: 0004 | train loss: 1.20928 | valid loss: 1.16370\n",
      "epoch: 0005 | train loss: 1.17250 | valid loss: 1.20958\n",
      "epoch: 0006 | train loss: 1.14189 | valid loss: 1.09602\n",
      "epoch: 0007 | train loss: 1.15141 | valid loss: 1.13243\n",
      "epoch: 0008 | train loss: 1.10272 | valid loss: 1.18558\n",
      "epoch: 0009 | train loss: 1.13354 | valid loss: 1.11572\n",
      "epoch: 0010 | train loss: 1.08082 | valid loss: 1.13081\n",
      "epoch: 0011 | train loss: 1.06556 | valid loss: 1.10491\n",
      "epoch: 0012 | train loss: 1.06744 | valid loss: 1.20369\n",
      "epoch: 0013 | train loss: 1.05664 | valid loss: 1.11915\n",
      "epoch: 0014 | train loss: 1.03099 | valid loss: 1.06311\n",
      "epoch: 0015 | train loss: 1.01823 | valid loss: 1.06339\n",
      "epoch: 0016 | train loss: 0.97943 | valid loss: 1.08308\n",
      "epoch: 0017 | train loss: 0.98594 | valid loss: 1.14906\n",
      "epoch: 0018 | train loss: 0.97017 | valid loss: 1.10722\n",
      "epoch: 0019 | train loss: 0.99486 | valid loss: 1.11903\n",
      "epoch: 0020 | train loss: 0.96617 | valid loss: 1.20367\n",
      "epoch: 0021 | train loss: 0.97150 | valid loss: 1.11751\n",
      "epoch: 0022 | train loss: 0.94048 | valid loss: 1.09167\n",
      "epoch: 0023 | train loss: 0.92981 | valid loss: 1.04294\n",
      "epoch: 0024 | train loss: 0.94486 | valid loss: 1.09340\n",
      "epoch: 0025 | train loss: 0.91168 | valid loss: 1.04906\n",
      "epoch: 0026 | train loss: 0.91451 | valid loss: 1.11586\n",
      "epoch: 0027 | train loss: 0.90786 | valid loss: 1.11932\n",
      "epoch: 0028 | train loss: 0.89201 | valid loss: 1.10246\n",
      "epoch: 0029 | train loss: 0.89406 | valid loss: 1.03689\n",
      "epoch: 0030 | train loss: 0.85640 | valid loss: 1.16853\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "for epoch in range(30):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.unsqueeze(-1).to(device)\n",
    "        #print(inputs.get_device())\n",
    "        #print(labels.get_device())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # labels_pred = softmax(outputs).argmax(1)\n",
    "        \n",
    "        # print(labels)\n",
    "        # print(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # train_correct += (labels == labels_pred.unsqueeze(-1)).float().sum() # ???\n",
    "        train_loss += [loss.item()]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_loss = []\n",
    "        for _, val_data in enumerate(val_dataloader, 0):\n",
    "            inputs, labels = val_data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.unsqueeze(-1).to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += [loss.item()]\n",
    "    # accuracy_train = train_correct / len(X_train)\n",
    "    print(\"epoch: %04d | train loss: %.5f | valid loss: %.5f\" %\n",
    "         (epoch + 1, np.mean(train_loss), np.mean(val_loss)))\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
